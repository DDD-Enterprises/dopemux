# Dopemux MCP Servers - Complete Docker Orchestration
# Based on ADR-007 (Routing Logic) and ADR-012 (MCP Integration Patterns)

services:
  # === CRITICAL PATH SERVERS (Priority: High) ===

  # Context7 - ALWAYS FIRST for documentation and API references
  context7:
    build:
      context: ./context7
      dockerfile: Dockerfile
    container_name: mcp-context7
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - CONTEXT7_API_KEY=${CONTEXT7_API_KEY}
      - CONTEXT7_ENDPOINT=${CONTEXT7_ENDPOINT}
      - MCP_SERVER_PORT=3002
    ports:
      - "3002:3002"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3002/health || nc -z localhost 3002"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    volumes:
      - mcp_context7_cache:/app/cache
    labels:
      - "mcp.role=critical_path"
      - "mcp.priority=highest"
      - "mcp.description=Documentation and API references"

  # Zen - Multi-model orchestration and complex decision making
  zen:
    build:
      context: ./zen
      dockerfile: Dockerfile
    container_name: mcp-zen
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - DISABLED_TOOLS=analyze,refactor,testgen,secaudit,docgen,tracer
      - DEFAULT_MODEL=auto
      - MCP_SERVER_PORT=3003
    ports:
      - "3003:3003"
    working_dir: /app
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    labels:
      - "mcp.role=critical_path"
      - "mcp.priority=highest"
      - "mcp.description=Multi-model orchestration"

  # Sequential Thinking - Multi-step reasoning and architectural analysis
  mas-sequential-thinking:
    build:
      context: ./mcp-server-mas-sequential-thinking
      dockerfile: Dockerfile
    container_name: mcp-mas-sequential-thinking
    restart: unless-stopped
    networks:
      - mcp-network
    env_file:
      - ./mcp-server-mas-sequential-thinking/.env
    environment:
      - MCP_SERVER_PORT=3011
    ports:
      - "3011:3011"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 3011 || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    volumes:
      - mcp_logs:/app/logs
      - mcp_cache:/app/cache
    labels:
      - "mcp.role=critical_path"
      - "mcp.priority=high"
      - "mcp.description=Multi-step reasoning and analysis"

  # === WORKFLOW SERVERS (Priority: Medium) ===

  # ConPort - Project memory and decision tracking
  conport:
    build:
      context: ./conport
      dockerfile: Dockerfile
    container_name: mcp-conport
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - MCP_SERVER_PORT=3004
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GOOGLE_API_KEY=${GEMINI_API_KEY}
      - VOYAGEAI_API_KEY=${VOYAGEAI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    ports:
      - "3004:3004"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 3004"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    volumes:
      - mcp_conport_data:/app/data
    labels:
      - "mcp.role=workflow"
      - "mcp.priority=medium"
      - "mcp.description=Project memory and decision tracking"

  # Task Master AI - Task management and PRD processing
  task-master-ai:
    build:
      context: ./task-master-ai
      dockerfile: Dockerfile
    container_name: mcp-task-master-ai
    restart: unless-stopped
    networks:
      - mcp-network
    env_file:
      - ./task-master-ai/.env
    environment:
      - MCP_SERVER_PORT=3005
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY}
    ports:
      - "3005:3005"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 3005 || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 60s
    volumes:
      - mcp_task_master_data:/app/data
      - mcp_task_master_logs:/app/logs
    labels:
      - "mcp.role=workflow"
      - "mcp.priority=medium"
      - "mcp.description=AI-powered task management and PRD processing"

  # Task Orchestrator - Advanced task orchestration and dependency management
  task-orchestrator:
    build:
      context: ./task-orchestrator
      dockerfile: Dockerfile
    container_name: mcp-task-orchestrator
    restart: unless-stopped
    networks:
      - mcp-network
    env_file:
      - ./task-orchestrator/.env
    environment:
      - MCP_SERVER_PORT=3014
      - JVM_HEAP_SIZE=512m
    ports:
      - "3014:3014"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 3014 || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 90s
    volumes:
      - mcp_task_orchestrator_data:/app/data
      - mcp_task_orchestrator_logs:/app/logs
    labels:
      - "mcp.role=workflow"
      - "mcp.priority=high"
      - "mcp.description=Task orchestration and dependency management with 37 tools"

  # Leantime Bridge - Connects existing Leantime to MCP network
  leantime-bridge:
    build:
      context: ./leantime-bridge
      dockerfile: Dockerfile
    container_name: mcp-leantime-bridge
    restart: unless-stopped
    networks:
      - mcp-network
      - leantime-net
    env_file:
      - ./leantime-bridge/.env
    environment:
      - MCP_SERVER_PORT=3015
      - LEANTIME_API_URL=http://leantime:80
      - LEANTIME_API_TOKEN=${LEAN_MCP_TOKEN}
    ports:
      - "3015:3015"
    depends_on:
      - milvus
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3015/health || nc -z localhost 3015 || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 45s
    volumes:
      - mcp_leantime_bridge_data:/app/data
      - mcp_leantime_bridge_logs:/app/logs
    labels:
      - "mcp.role=workflow"
      - "mcp.priority=high"
      - "mcp.description=Leantime project management integration bridge"

  # Serena - Code navigation, refactoring, LSP functionality
  serena:
    build:
      context: ./serena
      dockerfile: Dockerfile
    container_name: mcp-serena
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - MCP_SERVER_PORT=3006
    ports:
      - "3006:3006"
    # Health check disabled - server is functional but container lacks health check tools
    # healthcheck:
    #   test: ["CMD", "sh", "-c", "exit 0"]
    volumes:
      - mcp_serena_data:/app/data
      - /Users/hue/code/dopemux-mvp:/workspace/dopemux-mvp
    labels:
      - "mcp.role=workflow"
      - "mcp.priority=medium"
      - "mcp.description=Code navigation and refactoring with project access"


  # Milvus - Vector database for claude-context
  milvus:
    image: milvusdb/milvus:v2.4.16
    command: ["milvus", "run", "standalone"]
    container_name: mcp-milvus
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - ETCD_ENDPOINTS=milvus-etcd:2379
      - MINIO_ADDRESS=milvus-minio:9000
    ports:
      - "19530:19530"
    depends_on:
      - milvus-etcd
      - milvus-minio
    volumes:
      - mcp_milvus_data:/var/lib/milvus
    labels:
      - "mcp.role=storage"
      - "mcp.priority=medium"
      - "mcp.description=Vector database for semantic search"

  # Etcd for Milvus
  milvus-etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: mcp-milvus-etcd
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    volumes:
      - mcp_etcd_data:/etcd

  # MinIO for Milvus
  milvus-minio:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    container_name: mcp-milvus-minio
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
    command: minio server /minio_data --console-address ":9001"
    volumes:
      - mcp_minio_data:/minio_data

  # Claude Context - Semantic code search within repositories
  claude-context:
    build:
      context: ../../
      dockerfile: docker/mcp-servers/claude-context/Dockerfile
    platform: linux/amd64
    container_name: mcp-claude-context
    restart: unless-stopped
    networks:
      - mcp-network
    env_file:
      - ../../.env
    environment:
      - EMBEDDING_PROVIDER=VoyageAI
      - EMBEDDING_MODEL=voyage-code-3
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - VOYAGEAI_API_KEY=${VOYAGE_API_KEY}
      - VOYAGEAI_RERANK_MODEL=rerank-2.5
      - MILVUS_ADDRESS=milvus:19530
      - MCP_SERVER_PORT=3007
    ports:
      - "3007:3007"
    depends_on:
      - milvus
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep 'node.*index.js' | grep -v grep || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    volumes:
      - mcp_claude_context_data:/app/data
      - mcp_claude_context_cache:/root/.context
      - /Users/hue/code/dopemux-mvp:/workspace/dopemux-mvp:ro
    labels:
      - "mcp.role=research"
      - "mcp.priority=medium"
      - "mcp.description=Semantic code search"

  # === RESEARCH SERVERS (Priority: Low - Fallback Only) ===

  # Dopemux GPT Researcher - ADHD-optimized research with enhanced features
  dopemux-gpt-researcher:
    build:
      context: ../../services/dopemux-gpt-researcher
      dockerfile: Dockerfile
    container_name: dopemux-gpt-researcher
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - WORKSPACE_ID=/workspace/dopemux-mvp
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - EXA_API_KEY=${EXA_API_KEY}
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY}
      - CONPORT_ENABLED=true
      - WEBSOCKET_PORT=8001
      - API_PORT=8000
    ports:
      - "8000:8000"  # FastAPI backend
      - "8001:8001"  # WebSocket progress streaming
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 45s
    volumes:
      - mcp_dopemux_gpt_data:/app/data
      - mcp_dopemux_gpt_logs:/app/logs
      - mcp_dopemux_gpt_cache:/app/cache
      - /Users/hue/code/dopemux-mvp:/workspace/dopemux-mvp:ro
    depends_on:
      - conport
    labels:
      - "mcp.role=research"
      - "mcp.priority=highest"
      - "mcp.description=ADHD-optimized research with real-time progress and pause/resume"

  # Exa - Web research (ONLY when context7 lacks information)
  exa:
    build:
      context: ./exa
      dockerfile: Dockerfile
    container_name: mcp-exa
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - EXA_API_KEY=${EXA_API_KEY}
      - MCP_SERVER_PORT=3008
    ports:
      - "3008:3008"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3008/health || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    labels:
      - "mcp.role=research"
      - "mcp.priority=low"
      - "mcp.description=Web research fallback"

  # GPT Researcher - Autonomous deep research with comprehensive reports
  gptr-mcp:
    build:
      context: ./gptr-mcp
      dockerfile: Dockerfile
    container_name: mcp-gptr-mcp
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - MCP_SERVER_PORT=3009
    ports:
      - "3009:3009"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3009/health || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    volumes:
      - mcp_gptr_data:/app/data
      - mcp_gptr_logs:/app/logs
    labels:
      - "mcp.role=research"
      - "mcp.priority=high"
      - "mcp.description=Autonomous deep research and report generation"

  # GPT Researcher (STDIO) - container for proxy exec
  gptr-mcp-stdio:
    build:
      context: ../../
      dockerfile: docker/mcp-servers/gptr-mcp-stdio/Dockerfile
    container_name: mcp-gptr-stdio
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
    # No ports; stdio via docker exec
    command: ["tail", "-f", "/dev/null"]
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 10s
    labels:
      - "mcp.role=research"
      - "mcp.priority=high"
      - "mcp.description=STDIO bridge for GPT Researcher via proxy"

  # === QUALITY & UTILITY SERVERS (Priority: Medium) ===

  # MorphLLM Fast Apply - DISABLED (package not found in registry)
  # morphllm-fast-apply:
  #   build:
  #     context: ./morphllm-fast-apply
  #     dockerfile: Dockerfile
  #   container_name: mcp-morphllm-fast-apply
  #   restart: unless-stopped
  #   networks:
  #     - mcp-network
  #   environment:
  #     - MCP_SERVER_PORT=3011
  #   ports:
  #     - "3011:3011"
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:3011/health"]
  #     timeout: 10s
  #     retries: 3
  #     interval: 30s
  #     start_period: 30s
  #   labels:
  #     - "mcp.role=quality"
  #     - "mcp.priority=medium"
  #     - "mcp.description=Pattern-based transformations and bulk edits"

  # Desktop Commander - Desktop automation and system control
  desktop-commander:
    build:
      context: ./desktop-commander
      dockerfile: Dockerfile
    container_name: mcp-desktop-commander
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - MCP_SERVER_PORT=3012
      - DISPLAY=${DISPLAY:-:0}
    ports:
      - "3012:3012"
    volumes:
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - /tmp:/tmp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3012/health"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 30s
    labels:
      - "mcp.role=utility"
      - "mcp.priority=medium"
      - "mcp.description=Desktop automation and system control"

  # ClearThought - Structured reasoning and decision frameworks
  clear-thought:
    image: node:18-alpine
    container_name: mcp-clear-thought
    restart: unless-stopped
    networks:
      - mcp-network
    environment:
      - CLEAR_THOUGHT_TELEMETRY=off
      - MCP_SERVER_PORT=3013
    ports:
      - "3013:3013"
    working_dir: /app
    command: ["npx", "-y", "@waldzellai/clear-thought-onepointfive"]
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 3013 || exit 1"]
      timeout: 10s
      retries: 3
      interval: 30s
      start_period: 60s
    labels:
      - "mcp.role=reasoning"
      - "mcp.priority=high"
      - "mcp.description=Structured reasoning and decision frameworks"

# === NETWORKS ===
networks:
  mcp-network:
    external: true
    name: mcp-network
  # Connect to existing Leantime network for PM integration
  leantime-net:
    external: true
    name: leantime-net

# === VOLUMES ===
volumes:
  mcp_logs:
    external: true
    name: mcp_logs
  mcp_cache:
    external: true
    name: mcp_cache
  mcp_context7_cache:
    driver: local
    name: mcp_context7_cache
  mcp_conport_data:
    driver: local
    name: mcp_conport_data
  mcp_task_master_data:
    driver: local
    name: mcp_task_master_data
  mcp_task_master_logs:
    driver: local
    name: mcp_task_master_logs
  mcp_task_orchestrator_data:
    driver: local
    name: mcp_task_orchestrator_data
  mcp_task_orchestrator_logs:
    driver: local
    name: mcp_task_orchestrator_logs
  mcp_leantime_bridge_data:
    driver: local
    name: mcp_leantime_bridge_data
  mcp_leantime_bridge_logs:
    driver: local
    name: mcp_leantime_bridge_logs
  mcp_serena_data:
    driver: local
    name: mcp_serena_data
  mcp_claude_context_data:
    driver: local
    name: mcp_claude_context_data
  mcp_claude_context_cache:
    driver: local
    name: mcp_claude_context_cache
  mcp_gptr_data:
    driver: local
    name: mcp_gptr_data
  mcp_gptr_logs:
    driver: local
    name: mcp_gptr_logs
  mcp_milvus_data:
    driver: local
    name: mcp_milvus_data
  mcp_etcd_data:
    driver: local
    name: mcp_etcd_data
  mcp_minio_data:
    driver: local
    name: mcp_minio_data
  mcp_dopemux_gpt_data:
    driver: local
    name: mcp_dopemux_gpt_data
  mcp_dopemux_gpt_logs:
    driver: local
    name: mcp_dopemux_gpt_logs
  mcp_dopemux_gpt_cache:
    driver: local
    name: mcp_dopemux_gpt_cache
